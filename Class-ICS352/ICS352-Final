# Question 01:
# The titanic file contains data about passengers, it includes information about passenger name, class, sex, age, ticket, cabin, and survived.
# Use the decision tree classifier from Scikit Learn to predict whether a passenger survived or died in the tragedy.
# Plot the decision tree.
# Use KNN from Scikit Learn to predict whether a passenger survived or died in the tragedy. Run the model for different values of K.

#Code for answering question:
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Load Titanic data.
dftitanic = pd.read_csv("titanic.csv")

dftitanic['AgeMissing'] = dftitanic['Age'].isnull().astype(int)
dftitanic['Age'] = dftitanic['Age'].fillna(dftitanic['Age'].median())
dftitanic['Embarked'] = dftitanic['Embarked'].fillna('U') #Setting Embarked to U for Unknown.

le = LabelEncoder()
dftitanic["Embarked"] = le.fit_transform(dftitanic["Embarked"])
dftitanic["Sex"] = dftitanic["Sex"].replace({"male": 0, "female": 1}) #Male 0 and female 1 in the tree.

dftitanic = dftitanic.drop(["PassengerId", "Name", "Ticket", "Cabin"], axis=1) #Excludes these values from the tree

# Define features and target
X = dftitanic.drop("Survived", axis=1)
y = dftitanic["Survived"]

#Split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

#Train and show
#A max depth was used because it was unreadable otherwise.
tree = DecisionTreeClassifier(random_state=0, max_depth=5)
tree.fit(X_train, y_train)

#Predict
tree_preds = tree.predict(X_test)
tree_accuracy = accuracy_score(y_test, tree_preds)
print(f"Decision Tree Accuracy: {tree_accuracy:.4f}")

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(15, 10))
plot_tree(tree, feature_names=X.columns, class_names=["Died", "Survived"], filled=True)
plt.title("Decision Tree for Titanic Survival")
plt.show()

from sklearn.neighbors import KNeighborsClassifier

#Part 3. Using a For loop
for k in range(1, 11):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    knn_preds = knn.predict(X_test)
    acc = accuracy_score(y_test, knn_preds)
    print(f"KNN Accuracy with k={k}: {acc:.4f}") #Starts overfitting after a few runs.
